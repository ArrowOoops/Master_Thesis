% !TeX root = ../main.tex

\chapter{总结与展望}

本章首先对本文的工作进行一个全面的总结，然后对其中的不足之处进行分析和讨论，并且对未来的工作进行展望。


\section{工作总结}

%本节分别对三个研究点的内容进行总结。
本文从三个方面全面探讨了医学文本生成任务的隐私保护问题，为实际应用中的隐私保护提供了理论基础和实践指导。

%\subsection{医学文本生成任务的隐私攻击模型研究}
（1）医学文本生成任务的隐私攻击模型研究

%本章主要探讨了医学文本生成任务在训练和推断阶段的隐私泄露风险，以证明后续提出的隐私保护机制的重要性。首先，本章从语言模型的生成过程出发，详细介绍了如何为自然语言文本建模并生成后续文本，为后续分析医学文本生成模型的训练与推断阶段的执行过程奠定了基础。接着，本章分析了语言模型的记忆问题，并针对公开的预训练模型进行了攻击实验。同时，本章还提出了若干改进的攻击策略以增加攻击效果。此外，本章还讨论了攻击者在训练阶段如何尝试推断隐私数据以及破坏训练协议的可能攻击手段。最后，本章从推断阶段的攻击角度出发，阐述了攻击者可能尝试通过执行输入和标签重构攻击来恢复训练隐私数据的方式。通过在医学文本数据下训练的语言模型攻击实验，本章展示了语言模型记忆问题带来的隐私挑战。

本研究首先关注了医学文本生成任务在训练和推断阶段的隐私泄露风险，详细阐述了语言模型的生成过程及其记忆问题。针对公开的预训练模型实施了模型反演攻击，并提出了一些改进的攻击策略。同时，探讨了攻击者在训练阶段可能采用的攻击手段，通过实验分析了攻击效果，展示了语言模型记忆问题带来的隐私挑战。

%\subsection{医学文本生成任务训练阶段的隐私保护研究}
（2）医学文本生成任务训练阶段的隐私保护研究

%本章主要研究了在医疗文本生成任务训练阶段中的隐私保护问题。首先，明确了系统模型和威胁模型，并设计了安全目标。随后，提出了基于秘密共享的多方计算协议来保障数据机密性，并使用可信硬件保证执行过程的完整性。本章扩展了基于秘密共享的协议，使得可以构建复杂的Transformer结构。接着本章分析了协议的安全性，证明了协议满足设计目标。最后，本章通过实验验证了协议的有效性和高效性。

针对训练阶段的隐私保护问题，本研究明确了系统模型和威胁模型，并设计了安全目标。扩展了基于秘密共享的协议，使其能够构建复杂的Transformer结构。通过多方计算手段来保障数据机密性，利用可信硬件Intel SGX确保执行过程的完整性。为提高协议的执行效率，设计了一个可验证的外包计算方法。通过安全性分析和实验验证，证明了协议的有效性和高效性。

%\subsection{医学文本生成任务推断阶段的隐私保护研究}
（3）医学文本生成任务推断阶段的隐私保护研究

%为防止攻击者在推断阶段执行模型反演攻击，以恢复训练隐私数据，同时保持语言模型的表现效果，本章提出了一个基于差分隐私的新颖的隐私保护算法——选择差分隐私算法。首先，本章将介绍系统模型与设计目标，引入本章的保护对象与攻击者的行为。其次，介绍选择差分隐私的定义，并针对训练与推断阶段分别设计了隐私优化器与解码算法，作为两种提供选择差分隐私的方式。随后，对前述设计的隐私优化器与解码算法进行隐私性分析，以证明其满足差分隐私的定义。最后，通过设计实验说明选择差分隐私以及这两种保护方式的优势。

在推断阶段的隐私保护研究中，为阻止攻击者实施模型反演攻击以恢复训练隐私数据，同时保持语言模型的性能效果，本研究基于差分隐私提出了两种缓解医学文本生成任务语言模型的技术。针对训练与推断阶段分别设计了隐私优化器与解码算法，进行了隐私性分析，并通过实验验证了这两种保护方法的优势。


\section{未来展望}

本文对医学文本生成任务的隐私保护进行了深入研究，对于训练与推断阶段面临的攻击与效果进行了分析，并分别提出了隐私保护方法。尽管本文已经提出了相对安全的解决方案，但由于医学文本生成任务的复杂性，本文既要考虑语言模型相关的研究进展，也要跟进隐私保护技术的发展。此外，还受到公开数据集与预训练模型的制约。因此本文的工作在一些方面仍然存在局限性，需要进一步的深入研究。以下的方向可以作为未来研究的指引:

（1）研究更大规模语言模型的记忆问题

本文基于公开预训练模型，在医学文本数据集上进行微调训练，以得到针对该领域的语言模型。受困于训练资源以及训练语料，本文的语言模型相对于前沿的语言模型在规模上差距很多。因此，未来工作可以针对更大规模的语言模型进行记忆问题的分析，并使用本文提出的隐私保护算法来缓解记忆问题。

（2）提升多方安全计算函数协议的效率

由于在训练阶段中，数据隐私是最重要的考量，因此在满足同样隐私设定情况下提升协议效率是一项重要的问题。由于深度学习模型的特殊性，可以考虑在模型的部分层上执行一些参数量化与裁剪，以减少参数量与计算量。同时，针对该场景下的多方安全假设协议进行优化，减少各方之间的交互与执行时间。

（3）探索引入差分隐私的位置对语言模型表达能力的影响

本文分别对训练阶段与推断阶段加入差分隐私来缓解医学文本生成任务的语言模型的记忆问题。而在相同的隐私预算与加噪方式下，在模型的执行流程中，如分词编码、词向量、编码器与解码器的各个模块、最后映射到词表的线性变换等环节中加入差分隐私，模型表现效果的区别（如在损失与困惑度等指标下）仍需进一步研究。通过对这些问题的深入探究，可以使隐私保护算法在保护隐私的同时，尽量降低对模型效果的影响。
